{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-06T02:08:19.122509Z",
     "iopub.status.busy": "2025-02-06T02:08:19.122142Z",
     "iopub.status.idle": "2025-02-06T02:08:34.126520Z",
     "shell.execute_reply": "2025-02-06T02:08:34.125601Z",
     "shell.execute_reply.started": "2025-02-06T02:08:19.122474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary --quiet\n",
    "!pip install torchaudio --quiet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import sklearn\n",
    "import gc\n",
    "import zipfile\n",
    "import bisect\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import datetime\n",
    "import wandb\n",
    "import yaml\n",
    "import torchaudio.transforms as tat\n",
    "import torchaudio\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)\n",
    "\n",
    "\n",
    "### PHONEME LIST\n",
    "PHONEMES = [\n",
    "            '[SIL]',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',\n",
    "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
    "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
    "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
    "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
    "            'V',     'W',     'Y',     'Z',     'ZH',    '[SOS]', '[EOS]']\n",
    "\n",
    "\n",
    "config = {\n",
    "    'Name': 'Gopal', # Write your name here\n",
    "    'subset': 1.0, # Subset of dataset to use (1.0 == 100% of data)\n",
    "    'context': 30,\n",
    "    'archetype': 'diamond', # Default Values: pyramid, diamond, inverse-pyramid,cylinder\n",
    "    'activations': 'GELU',\n",
    "    'learning_rate': 0.001,\n",
    "    'dropout': 0.25,\n",
    "    # 'dropout': 0.05,\n",
    "    'optimizers': 'SGD',\n",
    "    'scheduler': 'ReduceLROnPlateau',\n",
    "    'epochs': 30,\n",
    "    'batch_size': 2048,\n",
    "    'weight_decay': 0.03,\n",
    "    # 'weight_initialization': None, # e.g kaiming_normal, kaiming_uniform, uniform, xavier_normal or xavier_uniform\n",
    "    'weight_initialization' : \"kaiming_normal\",\n",
    "    'augmentations': 'Both', # Options: [\"FreqMask\", \"TimeMask\", \"Both\", null]\n",
    "    'freq_mask_param': 4,\n",
    "    'time_mask_param': 8\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:08:36.930349Z",
     "iopub.status.busy": "2025-02-06T02:08:36.930000Z",
     "iopub.status.idle": "2025-02-06T02:08:40.318404Z",
     "shell.execute_reply": "2025-02-06T02:08:40.317258Z",
     "shell.execute_reply.started": "2025-02-06T02:08:36.930315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle==1.6.17\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105786 sha256=8e79e4e470d5fa0e17ebe0a4377e9cdcc7941fe3f89242bc9704f94fce28af9c\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/af/22/bf406f913dc7506a485e60dce8143741abd0a92a19337d83a3\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "  Attempting uninstall: kaggle\n",
      "    Found existing installation: kaggle 1.6.17\n",
      "    Uninstalling kaggle-1.6.17:\n",
      "      Successfully uninstalled kaggle-1.6.17\n",
      "Successfully installed kaggle-1.6.17\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade kaggle==1.6.17 --force-reinstall --no-deps\n",
    "!mkdir /root/.kaggle\n",
    "\n",
    "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
    "    # Put your kaggle username & key here\n",
    "    f.write('{\"username\":\"gopalvenki\",\"key\":\"3c76b5ea50eda8695b1fe0388683bb09\"}')\n",
    "\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:08:40.320048Z",
     "iopub.status.busy": "2025-02-06T02:08:40.319804Z",
     "iopub.status.idle": "2025-02-06T02:11:11.156719Z",
     "shell.execute_reply": "2025-02-06T02:11:11.155564Z",
     "shell.execute_reply.started": "2025-02-06T02:08:40.320025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 11785-spring-25-hw-1-p-2.zip to /kaggle/working\n",
      "100%|█████████████████████████████████████▉| 3.98G/3.98G [01:39<00:00, 39.2MB/s]\n",
      "100%|██████████████████████████████████████| 3.98G/3.98G [01:39<00:00, 43.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c 11785-spring-25-hw-1-p-2\n",
    "\n",
    "\n",
    "!unzip -qo /kaggle/working/11785-spring-25-hw-1-p-2.zip -d /kaggle/working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:11:11.159084Z",
     "iopub.status.busy": "2025-02-06T02:11:11.158777Z",
     "iopub.status.idle": "2025-02-06T02:11:11.179658Z",
     "shell.execute_reply": "2025-02-06T02:11:11.178807Z",
     "shell.execute_reply.started": "2025-02-06T02:11:11.159057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset class to load train and validation data\n",
    "\n",
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root, phonemes = PHONEMES, context=20, partition= \"train-clean-100\"): # Feel free to add more arguments\n",
    "\n",
    "        self.context    = context\n",
    "        self.phonemes   = phonemes\n",
    "        self.subset = config['subset']\n",
    "\n",
    "        \n",
    "        if config[\"augmentations\"] in [\"FreqMask\", \"Both\"]:\n",
    "            self.freq_masking = tat.FrequencyMasking(freq_mask_param = config[\"freq_mask_param\"])\n",
    "        else:\n",
    "            self.freq_masking = None\n",
    "\n",
    "        if config[\"augmentations\"] in [\"TimeMask\", \"Both\"]:\n",
    "            self.time_masking = tat.TimeMasking(time_mask_param = config[\"time_mask_param\"])\n",
    "        else:\n",
    "            self.time_masking = None\n",
    "\n",
    "\n",
    "        \n",
    "        data_path = os.path.join(root, partition)\n",
    "        self.mfcc_dir = os.path.join(data_path, 'mfcc')\n",
    "        self.transcript_dir = os.path.join(data_path, 'transcript')\n",
    "\n",
    "        \n",
    "        mfcc_names = sorted(os.listdir(self.mfcc_dir))\n",
    "        \n",
    "        transcript_names = sorted(os.listdir(self.transcript_dir))\n",
    "\n",
    "        # Compute size of data subset\n",
    "        subset_size = int(self.subset * len(mfcc_names))\n",
    "\n",
    "        # Select subset of data to use\n",
    "        mfcc_names = mfcc_names[:subset_size]\n",
    "        transcript_names = transcript_names[:subset_size]\n",
    "\n",
    "        # Making sure that we have the same no. of mfcc and transcripts\n",
    "        assert len(mfcc_names) == len(transcript_names)\n",
    "\n",
    "        self.mfccs, self.transcripts = [], []\n",
    "\n",
    "\n",
    "        # TODO: Iterate through mfccs and transcripts\n",
    "        for i in tqdm(range(len(mfcc_names))):\n",
    "\n",
    "            \n",
    "            mfcc = np.load(os.path.join(self.mfcc_dir, mfcc_names[i]))\n",
    "            mfccs_normalized = (mfcc - np.mean(mfcc, axis = 0, keepdims = True))/(np.std(mfcc, axis = 0, keepdims = True) + 0.0000001)\n",
    "            mfccs_normalized = torch.tensor(mfccs_normalized, dtype=torch.float32)\n",
    "            transcript = np.load(os.path.join(self.transcript_dir, transcript_names[i]))\n",
    "            transcript = transcript[1:-1]\n",
    "            transcript_indices = [self.phonemes.index(phonome) for phonome in transcript]\n",
    "            transcript_indices = torch.tensor(transcript_indices, dtype=torch.int64)\n",
    "            self.mfccs.append(mfccs_normalized)\n",
    "            self.transcripts.append(transcript_indices)\n",
    "\n",
    "        self.mfccs = torch.cat(self.mfccs, dim = 0)\n",
    "\n",
    "\n",
    "        self.transcripts = torch.cat(self.transcripts, dim = 0)\n",
    "\n",
    "        self.length = len(self.mfccs)\n",
    "\n",
    "        self.mfccs = nn.functional.pad(self.mfccs, (0,0, self.context, self.context), mode = \"constant\", value = 0)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "      x, y = zip(*batch)\n",
    "      x = torch.stack(x, dim=0)\n",
    "\n",
    "      # Apply augmentations with 70% probability (You can modify the probability)\n",
    "      if np.random.rand() < 0.70:\n",
    "        x = x.transpose(1, 2)  # Shape: (batch_size, freq, time)\n",
    "        x = self.freq_masking(x)\n",
    "        x = self.time_masking(x)\n",
    "        x = x.transpose(1, 2)  # Shape back to: (batch_size, time, freq)\n",
    "\n",
    "      return x, torch.tensor(y)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        # TODO: Based on context and offset, return a frame at given index with context frames to the left, and right.\n",
    "        # frames = NotImplemented\n",
    "        frames = self.mfccs[ind : (2 * self.context) + ind + 1 ]\n",
    "\n",
    "        # After slicing, you get an array of shape 2*context+1 x 28.\n",
    "\n",
    "        phonemes = self.transcripts[ind]\n",
    "\n",
    "        return frames, phonemes\n",
    "\n",
    "\n",
    "\n",
    "class AudioTestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, context=0, partition= \"test-clean\"): # Feel free to add more arguments\n",
    "\n",
    "        self.context    = context\n",
    "\n",
    "        data_path = os.path.join(root, partition)\n",
    "        self.mfcc_dir = os.path.join(data_path, 'mfcc')\n",
    "\n",
    "        mfcc_names = sorted(os.listdir(self.mfcc_dir))\n",
    "\n",
    "        self.mfccs = []\n",
    "\n",
    "\n",
    "        # TODO: Iterate through mfccs and transcripts\n",
    "        for i in tqdm(range(len(mfcc_names))):\n",
    "\n",
    " \n",
    "            mfcc = np.load(os.path.join(self.mfcc_dir, mfcc_names[i]))\n",
    "     \n",
    "            mfccs_normalized = (mfcc - np.mean(mfcc, axis = 0, keepdims = True))/np.std(mfcc, axis = 0, keepdims = True)\n",
    "     \n",
    "            mfccs_normalized = torch.tensor(mfccs_normalized, dtype=torch.float32)\n",
    "\n",
    "\n",
    "            self.mfccs.append(mfccs_normalized)\n",
    "            # self.transcripts.append(transcript_indices)\n",
    "\n",
    " \n",
    "        self.mfccs = torch.cat(self.mfccs, dim = 0)\n",
    "\n",
    "        self.length = len(self.mfccs)\n",
    "\n",
    "        self.mfccs = nn.functional.pad(self.mfccs, (0,0, self.context, self.context), mode = \"constant\", value = 0)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "      x, y = zip(*batch)\n",
    "      x = torch.stack(x, dim=0)\n",
    "\n",
    "      # Apply augmentations with 70% probability (You can modify the probability)\n",
    "      if np.random.rand() < 0.70:\n",
    "        x = x.transpose(1, 2)  # Shape: (batch_size, freq, time)\n",
    "        x = self.freq_masking(x)\n",
    "        x = self.time_masking(x)\n",
    "        x = x.transpose(1, 2)  # Shape back to: (batch_size, time, freq)\n",
    "\n",
    "      return x, torch.tensor(y)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "\n",
    "        frames = self.mfccs[ind : (2 * self.context) + ind + 1 ]\n",
    "        return frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:11:11.180667Z",
     "iopub.status.busy": "2025-02-06T02:11:11.180434Z",
     "iopub.status.idle": "2025-02-06T02:12:16.780304Z",
     "shell.execute_reply": "2025-02-06T02:12:16.779522Z",
     "shell.execute_reply.started": "2025-02-06T02:11:11.180648Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0a3d7244a146c493d5ad3410443e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3640f16172e240329191883373566ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967a1e01a9b241bbb7d05b2eee4efada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROOT = \"/kaggle/working/11785-s25-hw1p2\" # Define the root directory of the dataset here\n",
    "\n",
    "train_data = AudioDataset(ROOT, context = config['context'], partition= \"train-clean-100\")\n",
    "\n",
    "\n",
    "val_data = AudioDataset(ROOT, context = config['context'], partition = \"dev-clean\")\n",
    "\n",
    "test_data = AudioTestDataset(ROOT, context = config['context'], partition = \"test-clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:17.873498Z",
     "iopub.status.busy": "2025-02-06T02:12:17.873162Z",
     "iopub.status.idle": "2025-02-06T02:12:17.882841Z",
     "shell.execute_reply": "2025-02-06T02:12:17.881972Z",
     "shell.execute_reply.started": "2025-02-06T02:12:17.873468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size     :  2048\n",
      "Context        :  30\n",
      "Input size     :  1708\n",
      "Output symbols :  42\n",
      "Train dataset samples = 36091157, batches = 17623\n",
      "Validation dataset samples = 1928204, batches = 942\n",
      "Test dataset samples = 1934138, batches = 945\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = train_data,\n",
    "    # num_workers = 4,\n",
    "    num_workers = 4,\n",
    "    batch_size  = config['batch_size'],\n",
    "    pin_memory  = True,\n",
    "    shuffle     = True,\n",
    "    collate_fn = train_data.collate_fn\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = val_data,\n",
    "    num_workers = 0,\n",
    "    batch_size  = config['batch_size'],\n",
    "    pin_memory  = True,\n",
    "    shuffle     = False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = test_data,\n",
    "    num_workers = 2,\n",
    "    batch_size  = config['batch_size'],\n",
    "    pin_memory  = True,\n",
    "    shuffle     = False\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Batch size     : \", config['batch_size'])\n",
    "print(\"Context        : \", config['context'])\n",
    "print(\"Input size     : \", (2*config['context']+1)*28)\n",
    "print(\"Output symbols : \", len(PHONEMES))\n",
    "\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "print(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
    "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:19.976366Z",
     "iopub.status.busy": "2025-02-06T02:12:19.976037Z",
     "iopub.status.idle": "2025-02-06T02:12:27.011429Z",
     "shell.execute_reply": "2025-02-06T02:12:27.010391Z",
     "shell.execute_reply.started": "2025-02-06T02:12:19.976334Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 61, 28]) torch.Size([2048])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Testing code to check if your data loaders are working\n",
    "for i, data in enumerate(train_loader):\n",
    "    frames, phoneme = data\n",
    "    print(frames.shape, phoneme.shape)\n",
    "\n",
    "    # Visualize sample mfcc to inspect and verify everything is correctly done, especially augmentations\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frames[0].numpy().T, aspect='auto', origin='lower', cmap='viridis')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Feature Representation')\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:27.013256Z",
     "iopub.status.busy": "2025-02-06T02:12:27.012888Z",
     "iopub.status.idle": "2025-02-06T02:12:27.043520Z",
     "shell.execute_reply": "2025-02-06T02:12:27.042841Z",
     "shell.execute_reply.started": "2025-02-06T02:12:27.013216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Testing code to check if your validation data loaders are working\n",
    "all = []\n",
    "for i, data in enumerate(val_loader):\n",
    "    frames, phoneme = data\n",
    "    all.append(phoneme)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:27.045287Z",
     "iopub.status.busy": "2025-02-06T02:12:27.045073Z",
     "iopub.status.idle": "2025-02-06T02:12:27.055217Z",
     "shell.execute_reply": "2025-02-06T02:12:27.054373Z",
     "shell.execute_reply.started": "2025-02-06T02:12:27.045268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class OptimizedNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 2048),\n",
    "            nn.LayerNorm(2048),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Sequential(\n",
    "                ResidualBlock(2048, 1024, expansion=0.75),\n",
    "                SelfAttentionGate(1024),\n",
    "                nn.Dropout(0.3)\n",
    "            ),\n",
    "            \n",
    "            nn.Sequential(\n",
    "                nn.Linear(1024, 2048),\n",
    "                nn.LayerNorm(2048),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ),\n",
    "            \n",
    "            nn.Sequential(\n",
    "                ResidualBlock(2048, 1024, expansion=0.5),\n",
    "                SelfAttentionGate(1024),\n",
    "                nn.Dropout(0.3)\n",
    "            ),\n",
    "            \n",
    "            nn.Sequential(\n",
    "                ResidualBlock(1024, 1024, expansion=0.5),\n",
    "                nn.Dropout(0.2)\n",
    "            ),\n",
    "            \n",
    "            nn.Sequential(\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.LayerNorm(512),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(0.2),\n",
    "\n",
    "                nn.Linear(512, 256),\n",
    "                nn.LayerNorm(256),\n",
    "                nn.SiLU(),\n",
    "\n",
    "                nn.Linear(256, output_size)\n",
    "            )\n",
    "        )\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                nn.init.zeros_(m.bias)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        return self.model(x.flatten(1))\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, expansion=0.5):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(in_dim * expansion)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "            nn.LayerNorm(out_dim)\n",
    "        )\n",
    "        self.shortcut = nn.Linear(in_dim, out_dim) if in_dim != out_dim else nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x) + self.shortcut(x)\n",
    "\n",
    "class SelfAttentionGate(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(dim, max(128, dim//8)),  \n",
    "            nn.GELU(),\n",
    "            nn.Linear(max(128, dim//8), dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x * self.attn(x) + x  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:27.056400Z",
     "iopub.status.busy": "2025-02-06T02:12:27.056108Z",
     "iopub.status.idle": "2025-02-06T02:12:27.604599Z",
     "shell.execute_reply": "2025-02-06T02:12:27.603525Z",
     "shell.execute_reply.started": "2025-02-06T02:12:27.056372Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 2048]       3,500,032\n",
      "         LayerNorm-2                 [-1, 2048]           4,096\n",
      "              GELU-3                 [-1, 2048]               0\n",
      "           Dropout-4                 [-1, 2048]               0\n",
      "            Linear-5                 [-1, 1536]       3,147,264\n",
      "         LayerNorm-6                 [-1, 1536]           3,072\n",
      "              GELU-7                 [-1, 1536]               0\n",
      "            Linear-8                 [-1, 1024]       1,573,888\n",
      "         LayerNorm-9                 [-1, 1024]           2,048\n",
      "           Linear-10                 [-1, 1024]       2,098,176\n",
      "    ResidualBlock-11                 [-1, 1024]               0\n",
      "           Linear-12                  [-1, 128]         131,200\n",
      "             GELU-13                  [-1, 128]               0\n",
      "           Linear-14                 [-1, 1024]         132,096\n",
      "          Sigmoid-15                 [-1, 1024]               0\n",
      "SelfAttentionGate-16                 [-1, 1024]               0\n",
      "          Dropout-17                 [-1, 1024]               0\n",
      "           Linear-18                 [-1, 2048]       2,099,200\n",
      "        LayerNorm-19                 [-1, 2048]           4,096\n",
      "             SiLU-20                 [-1, 2048]               0\n",
      "          Dropout-21                 [-1, 2048]               0\n",
      "           Linear-22                 [-1, 1024]       2,098,176\n",
      "        LayerNorm-23                 [-1, 1024]           2,048\n",
      "             GELU-24                 [-1, 1024]               0\n",
      "           Linear-25                 [-1, 1024]       1,049,600\n",
      "        LayerNorm-26                 [-1, 1024]           2,048\n",
      "           Linear-27                 [-1, 1024]       2,098,176\n",
      "    ResidualBlock-28                 [-1, 1024]               0\n",
      "           Linear-29                  [-1, 128]         131,200\n",
      "             GELU-30                  [-1, 128]               0\n",
      "           Linear-31                 [-1, 1024]         132,096\n",
      "          Sigmoid-32                 [-1, 1024]               0\n",
      "SelfAttentionGate-33                 [-1, 1024]               0\n",
      "          Dropout-34                 [-1, 1024]               0\n",
      "           Linear-35                  [-1, 512]         524,800\n",
      "        LayerNorm-36                  [-1, 512]           1,024\n",
      "             GELU-37                  [-1, 512]               0\n",
      "           Linear-38                 [-1, 1024]         525,312\n",
      "        LayerNorm-39                 [-1, 1024]           2,048\n",
      "         Identity-40                 [-1, 1024]               0\n",
      "    ResidualBlock-41                 [-1, 1024]               0\n",
      "          Dropout-42                 [-1, 1024]               0\n",
      "           Linear-43                  [-1, 512]         524,800\n",
      "        LayerNorm-44                  [-1, 512]           1,024\n",
      "             GELU-45                  [-1, 512]               0\n",
      "          Dropout-46                  [-1, 512]               0\n",
      "           Linear-47                  [-1, 256]         131,328\n",
      "        LayerNorm-48                  [-1, 256]             512\n",
      "             SiLU-49                  [-1, 256]               0\n",
      "           Linear-50                   [-1, 42]          10,794\n",
      "================================================================\n",
      "Total params: 19,930,154\n",
      "Trainable params: 19,930,154\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.39\n",
      "Params size (MB): 76.03\n",
      "Estimated Total Size (MB): 76.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE  = (2*config['context'] + 1) * 28 # Why is this the case?\n",
    "model       = OptimizedNetwork(INPUT_SIZE, len(train_data.phonemes)).to(device)\n",
    "summary(model, frames[0].to(device).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:33.190631Z",
     "iopub.status.busy": "2025-02-06T02:12:33.190242Z",
     "iopub.status.idle": "2025-02-06T02:12:48.473575Z",
     "shell.execute_reply": "2025-02-06T02:12:48.472768Z",
     "shell.execute_reply.started": "2025-02-06T02:12:33.190597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install triton>=2.2.0 lion-pytorch\n",
    "\n",
    "from lion_pytorch import Lion\n",
    "\n",
    "optimizer = Lion(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,  \n",
    "    weight_decay=1e-2,  \n",
    "    use_triton=False  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:48.475114Z",
     "iopub.status.busy": "2025-02-06T02:12:48.474662Z",
     "iopub.status.idle": "2025-02-06T02:12:48.479646Z",
     "shell.execute_reply": "2025-02-06T02:12:48.478672Z",
     "shell.execute_reply.started": "2025-02-06T02:12:48.475090Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "total_steps = config['epochs'] * len(train_loader)  \n",
    "\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3, \n",
    "    total_steps=total_steps,\n",
    "    pct_start=0.3,  \n",
    "    anneal_strategy='cos',  \n",
    "    final_div_factor=100 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:48.481585Z",
     "iopub.status.busy": "2025-02-06T02:12:48.481349Z",
     "iopub.status.idle": "2025-02-06T02:12:48.502277Z",
     "shell.execute_reply": "2025-02-06T02:12:48.501523Z",
     "shell.execute_reply.started": "2025-02-06T02:12:48.481563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:48.503738Z",
     "iopub.status.busy": "2025-02-06T02:12:48.503417Z",
     "iopub.status.idle": "2025-02-06T02:12:48.523302Z",
     "shell.execute_reply": "2025-02-06T02:12:48.522476Z",
     "shell.execute_reply.started": "2025-02-06T02:12:48.503684Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-1401778c2c1d>:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=True)\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "torch.set_float32_matmul_precision('high')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:48.524476Z",
     "iopub.status.busy": "2025-02-06T02:12:48.524196Z",
     "iopub.status.idle": "2025-02-06T02:12:48.540113Z",
     "shell.execute_reply": "2025-02-06T02:12:48.539142Z",
     "shell.execute_reply.started": "2025-02-06T02:12:48.524426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion):\n",
    "\n",
    "    model.train()\n",
    "    tloss, tacc = 0, 0 # Monitoring loss and accuracy\n",
    "    batch_bar   = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
    "\n",
    "    for i, (frames, phonemes) in enumerate(dataloader):\n",
    "\n",
    "        ### Initialize Gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        frames      = frames.to(device)\n",
    "        phonemes    = phonemes.to(device)\n",
    "\n",
    "        with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "            ### Forward Propagation\n",
    "            logits  = model(frames)\n",
    "\n",
    "            ### Loss Calculation\n",
    "            loss    = criterion(logits, phonemes)\n",
    "\n",
    "        ### Backward Propagation\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # OPTIONAL: You can add gradient clipping here, if you face issues of exploding gradients\n",
    "\n",
    "        ### Gradient Descent\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        tloss   += loss.item()\n",
    "        tacc    += torch.sum(torch.argmax(logits, dim= 1) == phonemes).item()/logits.shape[0]\n",
    "\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(tloss / (i + 1))),\n",
    "                              acc=\"{:.04f}%\".format(float(tacc*100 / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "        ### Release memory\n",
    "        del frames, phonemes, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    batch_bar.close()\n",
    "    tloss   /= len(train_loader)\n",
    "    tacc    /= len(train_loader)\n",
    "\n",
    "\n",
    "    return tloss, tacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:48.541276Z",
     "iopub.status.busy": "2025-02-06T02:12:48.541001Z",
     "iopub.status.idle": "2025-02-06T02:12:48.554056Z",
     "shell.execute_reply": "2025-02-06T02:12:48.553254Z",
     "shell.execute_reply.started": "2025-02-06T02:12:48.541242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def eval(model, dataloader):\n",
    "\n",
    "    model.eval() # set model in evaluation mode\n",
    "    vloss, vacc = 0, 0 # Monitoring loss and accuracy\n",
    "    batch_bar   = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
    "\n",
    "    for i, (frames, phonemes) in enumerate(dataloader):\n",
    "\n",
    "        ### Move data to device (ideally GPU)\n",
    "        frames      = frames.to(device)\n",
    "        phonemes    = phonemes.to(device)\n",
    "\n",
    "        # makes sure that there are no gradients computed as we are not training the model now\n",
    "        with torch.inference_mode():\n",
    "            ### Forward Propagation\n",
    "            logits  = model(frames)\n",
    "            ### Loss Calculation\n",
    "            loss    = criterion(logits, phonemes)\n",
    "\n",
    "        vloss   += loss.item()\n",
    "        vacc    += torch.sum(torch.argmax(logits, dim= 1) == phonemes).item()/logits.shape[0]\n",
    "\n",
    "        # Do you think we need loss.backward() and optimizer.step() here?\n",
    "\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(vloss / (i + 1))),\n",
    "                              acc=\"{:.04f}%\".format(float(vacc*100 / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "        ### Release memory\n",
    "        del frames, phonemes, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close()\n",
    "    vloss   /= len(val_loader)\n",
    "    vacc    /= len(val_loader)\n",
    "\n",
    "    return vloss, vacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:48.554919Z",
     "iopub.status.busy": "2025-02-06T02:12:48.554689Z",
     "iopub.status.idle": "2025-02-06T02:12:55.747772Z",
     "shell.execute_reply": "2025-02-06T02:12:55.747006Z",
     "shell.execute_reply.started": "2025-02-06T02:12:48.554899Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgopalakt\u001b[0m (\u001b[33mgopalakt-carnegie-mellon-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"c59e320dfcb249ed2a66979ac2fff03bbddd8f3c\") #API Key is in your wandb account, under settings (wandb.ai/settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:12:55.749934Z",
     "iopub.status.busy": "2025-02-06T02:12:55.749527Z",
     "iopub.status.idle": "2025-02-06T02:13:02.625760Z",
     "shell.execute_reply": "2025-02-06T02:13:02.625031Z",
     "shell.execute_reply.started": "2025-02-06T02:12:55.749911Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250206_021255-1ealgvvf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/gopalakt-carnegie-mellon-university/h1p2/runs/1ealgvvf' target=\"_blank\">first-major-run11</a></strong> to <a href='https://wandb.ai/gopalakt-carnegie-mellon-university/h1p2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gopalakt-carnegie-mellon-university/h1p2' target=\"_blank\">https://wandb.ai/gopalakt-carnegie-mellon-university/h1p2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gopalakt-carnegie-mellon-university/h1p2/runs/1ealgvvf' target=\"_blank\">https://wandb.ai/gopalakt-carnegie-mellon-university/h1p2/runs/1ealgvvf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create your wandb run\n",
    "run = wandb.init(\n",
    "    name    = \"first-major-run11\", ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
    "    reinit  = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "    id     = \"1ealgvvf\", ### Insert specific run id here if you want to resume a previous run\n",
    "    resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project = \"h1p2\", ### Project should be created in your wandb account\n",
    "    config  = config ### Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:13:02.626984Z",
     "iopub.status.busy": "2025-02-06T02:13:02.626697Z",
     "iopub.status.idle": "2025-02-06T02:13:02.634987Z",
     "shell.execute_reply": "2025-02-06T02:13:02.634216Z",
     "shell.execute_reply.started": "2025-02-06T02:13:02.626959Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/wandb/run-20250206_021255-1ealgvvf/files/model_arch.txt']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Save your model architecture as a string with str(model)\n",
    "model_arch  = str(model)\n",
    "\n",
    "### Save it in a txt file\n",
    "arch_file   = open(\"model_arch.txt\", \"w\")\n",
    "file_write  = arch_file.write(model_arch)\n",
    "arch_file.close()\n",
    "\n",
    "### log it in your wandb run with wandb.save()\n",
    "wandb.save('model_arch.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T05:08:07.190182Z",
     "iopub.status.busy": "2025-02-06T05:08:07.189858Z",
     "iopub.status.idle": "2025-02-06T05:08:07.772044Z",
     "shell.execute_reply": "2025-02-06T05:08:07.771153Z",
     "shell.execute_reply.started": "2025-02-06T05:08:07.190154Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Resuming training from epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-4b82c42c3238>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(restored_checkpoint.name)\n"
     ]
    }
   ],
   "source": [
    "# Restore checkpoint from wandb\n",
    "restored_checkpoint = wandb.restore(f'checkpoint_epoch_{47}.pth')  # Replace with specific epoch\n",
    "\n",
    "# Load checkpoint into model and optimizer\n",
    "checkpoint = torch.load(restored_checkpoint.name)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "if checkpoint.get('scheduler_state_dict'):\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "# Resume from the epoch saved in the checkpoint\n",
    "start_epoch = checkpoint['epoch']\n",
    "print(f\"Resuming training from epoch {start_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T03:47:25.849797Z",
     "iopub.status.busy": "2025-02-06T03:47:25.849484Z",
     "iopub.status.idle": "2025-02-06T05:07:58.267749Z",
     "shell.execute_reply": "2025-02-06T05:07:58.266405Z",
     "shell.execute_reply.started": "2025-02-06T03:47:25.849772Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/17623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 84.9835%\tTrain Loss 0.4359\t Learning Rate 0.0000001\n",
      "\tVal Acc 85.9056%\tVal Loss 0.4211\n",
      "\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/17623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 84.9826%\tTrain Loss 0.4358\t Learning Rate 0.0000001\n",
      "\tVal Acc 85.9059%\tVal Loss 0.4211\n",
      "\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/17623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.0358%\tTrain Loss 0.4342\t Learning Rate 0.0000001\n",
      "\tVal Acc 85.9069%\tVal Loss 0.4212\n",
      "\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/17623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 84.9956%\tTrain Loss 0.4354\t Learning Rate 0.0000001\n",
      "\tVal Acc 85.9066%\tVal Loss 0.4211\n",
      "\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d2e8fdef5f4fecb19327c3924e6899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/17623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9f3ab36993bf>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcurr_lr\u001b[0m                 \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-c5bdd50cdc1b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m### Gradient Descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate over number of epochs to train and evaluate your model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "for epoch in range(start_epoch, config['epochs']):\n",
    "\n",
    "    print(\"\\nEpoch {}/{}\".format(epoch+1, config['epochs']))\n",
    "\n",
    "    curr_lr                 = float(optimizer.param_groups[0]['lr'])\n",
    "    train_loss, train_acc   = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc       = eval(model, val_loader)\n",
    "\n",
    "    print(\"\\tTrain Acc {:.04f}%\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_acc*100, train_loss, curr_lr))\n",
    "    print(\"\\tVal Acc {:.04f}%\\tVal Loss {:.04f}\".format(val_acc*100, val_loss))\n",
    "\n",
    "\n",
    "    wandb.log({'train_acc': train_acc*100, 'train_loss': train_loss,\n",
    "               'val_acc': val_acc*100, 'valid_loss': val_loss, 'lr': curr_lr})\n",
    "\n",
    "    # save_checkpoint(model, optimizer, epoch, train_loss, \"checkpoint_epoch_2.pth\")\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss\n",
    "    }\n",
    "\n",
    "    # Save checkpoint locally\n",
    "    checkpoint_filename = f'checkpoint_epoch_{epoch + 1}.pth'\n",
    "    torch.save(checkpoint, checkpoint_filename)\n",
    "\n",
    "    # Save the checkpoint to wandb\n",
    "    wandb.save(checkpoint_filename)\n",
    "    # scheduler.step(val_loss)\n",
    "    # schedular.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T03:47:22.489713Z",
     "iopub.status.busy": "2025-02-06T03:47:22.489339Z",
     "iopub.status.idle": "2025-02-06T03:47:22.494628Z",
     "shell.execute_reply": "2025-02-06T03:47:22.493925Z",
     "shell.execute_reply.started": "2025-02-06T03:47:22.489682Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = Lion(\n",
    "    model.parameters(),\n",
    "    # lr=3e-4,\n",
    "    lr = 0.0000001,\n",
    "    weight_decay=1e-2,  \n",
    "    use_triton=False  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total_steps = config['epochs'] * len(train_loader)  \n",
    "\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,  \n",
    "    total_steps=total_steps,\n",
    "    pct_start=0.3,  \n",
    "    anneal_strategy='cos',  \n",
    "    final_div_factor=100  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T02:13:26.471293Z",
     "iopub.status.busy": "2025-02-06T02:13:26.470965Z",
     "iopub.status.idle": "2025-02-06T02:13:26.476770Z",
     "shell.execute_reply": "2025-02-06T02:13:26.475960Z",
     "shell.execute_reply.started": "2025-02-06T02:13:26.471267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'Name': 'Gopal', # Write your name here\n",
    "    'subset': 1.0, # Subset of dataset to use (1.0 == 100% of data)\n",
    "    'context': 30,\n",
    "    'archetype': 'diamond', # Default Values: pyramid, diamond, inverse-pyramid,cylinder\n",
    "    'activations': 'GELU',\n",
    "    'learning_rate': 0.001,\n",
    "    'dropout': 0.25,\n",
    "    # 'dropout': 0.05,\n",
    "    'optimizers': 'SGD',\n",
    "    'scheduler': 'ReduceLROnPlateau',\n",
    "    'epochs': 50,\n",
    "    'batch_size': 2048,\n",
    "    'weight_decay': 0.03,\n",
    "    # 'weight_initialization': None, # e.g kaiming_normal, kaiming_uniform, uniform, xavier_normal or xavier_uniform\n",
    "    'weight_initialization' : \"kaiming_normal\",\n",
    "    'augmentations': 'Both', # Options: [\"FreqMask\", \"TimeMask\", \"Both\", null]\n",
    "    'freq_mask_param': 4,\n",
    "    'time_mask_param': 8\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T03:17:56.826595Z",
     "iopub.status.busy": "2025-02-03T03:17:56.826300Z",
     "iopub.status.idle": "2025-02-03T03:17:56.831414Z",
     "shell.execute_reply": "2025-02-03T03:17:56.830543Z",
     "shell.execute_reply.started": "2025-02-03T03:17:56.826557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T05:08:15.557036Z",
     "iopub.status.busy": "2025-02-06T05:08:15.556738Z",
     "iopub.status.idle": "2025-02-06T05:08:15.562670Z",
     "shell.execute_reply": "2025-02-06T05:08:15.561875Z",
     "shell.execute_reply.started": "2025-02-06T05:08:15.557012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    ### What you call for model to perform inference?\n",
    "    model.eval() # TODO train or eval?\n",
    "\n",
    "    ### List to store predicted phonemes of test data\n",
    "    test_predictions = []\n",
    "\n",
    "    ### Which mode do you need to avoid gradients?\n",
    "    with torch.inference_mode(): # TODO\n",
    "\n",
    "        for i, mfccs in enumerate(tqdm(test_loader)):\n",
    "\n",
    "            mfccs   = mfccs.to(device)\n",
    "\n",
    "            logits  = model(mfccs)\n",
    "\n",
    "            ### Get most likely predicted phoneme with argmax\n",
    "            predicted_phonemes = torch.argmax(logits, dim= 1)\n",
    "\n",
    "            ### How do you store predicted_phonemes with test_predictions? Hint, look at eval\n",
    "            # Remember the phonemes were converted to their corresponding integer indices earlier, and the results of the argmax is a list of the indices of the predicted phonemes.\n",
    "            # So how do you get and store the actual predicted phonemes\n",
    "            # TODO: Store predicted_phonemes\n",
    "            # test_predictions.append(PHONEMES[predicted_phonemes])\n",
    "            test_predictions.extend([PHONEMES[idx] for idx in predicted_phonemes.cpu().tolist()])\n",
    "\n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T05:08:15.867277Z",
     "iopub.status.busy": "2025-02-06T05:08:15.866978Z",
     "iopub.status.idle": "2025-02-06T05:08:35.318535Z",
     "shell.execute_reply": "2025-02-06T05:08:35.317408Z",
     "shell.execute_reply.started": "2025-02-06T05:08:15.867252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea29edd53a8f4212a38d283ce12e8fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/945 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d72890e9e10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    }
   ],
   "source": [
    "predictions = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T05:08:36.971280Z",
     "iopub.status.busy": "2025-02-06T05:08:36.970922Z",
     "iopub.status.idle": "2025-02-06T05:08:38.307430Z",
     "shell.execute_reply": "2025-02-06T05:08:38.306531Z",
     "shell.execute_reply.started": "2025-02-06T05:08:36.971243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Create CSV file with predictions\n",
    "with open(\"./submission11.csv\", \"w+\") as f:\n",
    "    f.write(\"id,label\\n\")\n",
    "    for i in range(len(predictions)):\n",
    "        f.write(\"{},{}\\n\".format(i, predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Submit to kaggle competition using kaggle API (Uncomment below to use)\n",
    "!kaggle competitions submit -c 11785-spring-25-hw-1-p-2 -f /content/submission.csv -m \"Test Submission\"\n",
    "\n",
    "### However, its always safer to download the csv file and then upload to kaggle"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
